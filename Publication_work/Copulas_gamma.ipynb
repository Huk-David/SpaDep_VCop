{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with copulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a list of Us as follows:\n",
    " - For each location, we start with 16 observations corresponding to 16 sublocations. We treat these as seperate locations for the rest of this work.\n",
    " - The list of Us will be of length 2002 [day]. Each of these 2002 elements will be an array of length 4727 [Us] corresponding to the Us of each location for the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "%matplotlib inline\n",
    "from scipy.optimize import dual_annealing\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from collections import Counter\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "from scipy.spatial import distance_matrix\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from math import sqrt\n",
    "from joblib import Parallel, delayed\n",
    "import psutil\n",
    "import math\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "import scipy.sparse\n",
    "sys.path.append('../')\n",
    "from parallel.backends import BackendDummy as Backend\n",
    "backend = Backend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Checkpoints/uk_rain_DGLM_HConvLSTM_tdscale_gamma_hurdle/lightning_logs/version_7/', 'Checkpoints/uk_rain_DGLM_HConvLSTM_tdscale_gamma_hurdle/lightning_logs/version_7/checkpoints/epoch=12-step=25572-val_loss_loss=-0.391-val_metric_mse_rain=21.531.ckpt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### load gamma\n",
    "model_version = 7\n",
    "target_distribution = \"gamma_hurdle\"\n",
    "base_nn = \"HConvLSTM_tdscale\" #(Keep this fixed)\n",
    "\n",
    "# Run this to get the prediction data in a variable named city_data\n",
    "# Getting data\n",
    "sys.path.append('../')\n",
    "import glms\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "path_ = f\"Checkpoints/uk_rain_DGLM_{base_nn}_{target_distribution}/lightning_logs/version_{model_version}/\"\n",
    "ckpt_path = glms.NeuralDGLM.get_ckpt_path(os.path.join(path_,\"checkpoints\"))\n",
    "print([path_,ckpt_path])\n",
    "scaler_features, scaler_target = glms.NeuralDGLM.load_scalers(path_)\n",
    "model = glms.NeuralDGLM.load_from_checkpoint(ckpt_path, save_hparams=False, scaler_features=scaler_features, scaler_target=scaler_target)\n",
    "model.freeze()\n",
    "model.eval()\n",
    "\n",
    "test_output = pickle.load( open(os.path.join(path_,\"test_output_2014_2019-07.pkl\"),\"rb\") )\n",
    "#########\n",
    "\n",
    "# create list of locations\n",
    "loc_lat_lon = list(test_output.keys())\n",
    "output_keys = ['pred_mu', 'pred_disp', 'target_did_rain', 'target_rain_value', 'date', 'pred_p']\n",
    "\n",
    "#'lat_50.95_49.35_lon_-4.55_-2.95' has no data after week indexed 255, so I did not consider it.\n",
    "loc_lat_lon.remove('lat_50.95_49.35_lon_-4.55_-2.95')\n",
    "#  'pred_mu', 'pred_disp', 'target_did_rain', 'target_rain_value', 'date', 'pred_p'\n",
    "\n",
    "# formatting data\n",
    "gamma_outputs = [[[],[],[],[],[],[]] for places in range(len(loc_lat_lon))] \n",
    "for location_idx in range(len(loc_lat_lon)):\n",
    "    gamma_outputs[location_idx].append([float(loc_lat_lon[location_idx].split('_')[i]) for i in [1,2,4,5]])\n",
    "    gamma_outputs[location_idx].append(test_output[loc_lat_lon[location_idx]]['mask'][0][0])\n",
    "    for output_idx in range(6):\n",
    "        for week in range(286):\n",
    "            for day in range(7):\n",
    "                #check for date, as date is formatted differently from the rest.\n",
    "                if output_idx==4:\n",
    "                    if day==0:\n",
    "                        gamma_outputs[location_idx][output_idx].append(np.array(test_output[loc_lat_lon[location_idx]][output_keys[output_idx]][week],dtype='datetime64[D]'))\n",
    "                    else:\n",
    "                        gamma_outputs[location_idx][output_idx].append('')                   \n",
    "                else:\n",
    "                    gamma_outputs[location_idx][output_idx].append(test_output[loc_lat_lon[location_idx]][output_keys[output_idx]][week][day])\n",
    "# Loading data for Us\n",
    "with open('g_us.txt','rb') as f:\n",
    "    g_us = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of idexes corresponding to land locations\n",
    "is_loc_land = [] # boolean vector indicating for each location if it is land\n",
    "                 #[0,1,...,0] length=#locations\n",
    "                 # if it is not land, that location is getting skipped in gamma_outputs\n",
    "                 # WILL NEED TO TAKE THIS INTO ACCOUNT ONCE I PLOT THE MAP\n",
    "for loc in loc_lat_lon:\n",
    "    for week in range(1):\n",
    "        for day in range(1):\n",
    "            for row in range(4):\n",
    "                for column in range(4):\n",
    "                    if test_output[loc]['mask'][week][day][row][column]==1:\n",
    "                        is_loc_land.append(1)\n",
    "                    else:\n",
    "                        is_loc_land.append(0)\n",
    "\n",
    "idx_land = []                       \n",
    "for idx,b in enumerate(is_loc_land):\n",
    "    if b==1:\n",
    "        idx_land.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct any code-approximation related errors\n",
    "for day in range(len(g_us)):\n",
    "    for location in range(len(g_us[0])):\n",
    "        if g_us[day][location]==0:\n",
    "            g_us[day][location]=0.0001\n",
    "        if g_us[day][location]==1:\n",
    "            g_us[day][location]=0.999\n",
    "        g_us[day][location]=abs(g_us[day][location])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copula classes\n",
    "\n",
    "# Gaussian\n",
    "# This class is with sigma fixed at 1 - This is what is used for the rest of this notebook\n",
    "class norm_cop_loconly():\n",
    "\n",
    "    def __init__(self,L=np.array([[0,1,1],[1,0,1],[1,1,0]])):\n",
    "        '''\n",
    "        L is location matrix: n x n\n",
    "        '''\n",
    "        self.N=L.shape[0]\n",
    "        self.L=L\n",
    "\n",
    "    def sim(self,theta,draws=3,as_x=False):\n",
    "        '''\n",
    "        Returns: [ [m [draws of length n] for day t+1],..., [m [draws of length n] for day t+T_(depending on prediction matricies X_all)] ]\n",
    "        So to get the samples from day t+1: sim[1-1]\n",
    "        To get k th draw from samples at day t+T: sim[T-1][k-1]\n",
    "        To get u for 3rd location of kth drw for day T: sim[T-1][k-1][3-1]'''\n",
    "        cov_mat=Matern(length_scale=theta[0],nu=theta[1]).__call__(self.L)\n",
    "        #sigma should be in theta ##############################\n",
    "\n",
    "        if as_x==True:\n",
    "            return [scs.multivariate_normal.rvs(mean=np.zeros(self.N),cov=cov_mat) for i in range(draws) ] \n",
    "        if as_x==False:\n",
    "            Us=[np.zeros(self.N) for i in range(draws)] \n",
    "            for i in range(draws):\n",
    "                Us[i]=[scs.multivariate_normal.cdf(y,mean=0,cov=cov_mat[idx,idx]) for idx,y in enumerate(scs.multivariate_normal.rvs(mean=np.zeros(self.N),cov=cov_mat))]\n",
    "            return Us\n",
    "\n",
    "    \n",
    "    def nll(self,theta,data):\n",
    "        '''\n",
    "        theta: [sigma,p0,v0,p1,v1] vector of parameters for the Matern Kernel\n",
    "        data: [[u1,..,un],...,[...]] one set of (n: one for each location) us for each day 1 to T (T is the number of predictor matricies).\n",
    "        '''\n",
    "        nll=0\n",
    "        cov_mat=Matern(length_scale=theta[0],nu=theta[1]).__call__(self.L) \n",
    "        #sigma should be in theta ##############################\n",
    "\n",
    "        for day in range(len(data)):\n",
    "            #nll for the copula density: joint and marginals\n",
    "            nll+=scs.multivariate_normal.logpdf([scs.norm.ppf(obs,loc=0,scale=cov_mat[idx,idx]) for idx,obs in enumerate(data[day])],mean=np.zeros(self.N),cov=cov_mat) \n",
    "            nll+=-np.sum([scs.norm.logpdf(obs,loc=0,scale=cov_mat[idx,idx]) for idx,obs in enumerate(data[day])])\n",
    "        return -nll\n",
    "\n",
    "# Clayton\n",
    "class Clayton():\n",
    "    def __init__(self,n=2):\n",
    "        '''\n",
    "        Class to fit and work with a Clayton copula, using two functions.\n",
    "        sim: simulated [0,1] values using this copula density.\n",
    "        eval_nll: evaluate the negative log likelihood based on given data.\n",
    "        To use the class, the dimension of the data is needed.\n",
    "        n: dimension of data\n",
    "        '''\n",
    "        self.n=n # dimension\n",
    "\n",
    "    def sim(draws=10,theta=1):\n",
    "        '''\n",
    "        Simulates m draws from the Clayton copula density\n",
    "        '''\n",
    "        # not sure how yet.\n",
    "\n",
    "    def eval_nll(self,theta=10,data=[[0.4,0.6],[0.001,0.01],[0.1,0.1],[0.8,0.9],[0.1,0.0001],[0.3,0.1]]):\n",
    "        '''\n",
    "        theta: the parameter of the Clayton copula in [0,inf).\n",
    "        \n",
    "        data: [[u1_(k=1) ,..., un_(k=1)] ,..., [u1_(k=k) ,..., un(k=k)]] one set of (n of them: one for each location) us for each day 1 to T.\n",
    "        '''\n",
    "        # Compute the pdf by looping over each day, and adding the nll for that day to the result. \n",
    "\n",
    "        #### second atempt\n",
    "        nll=0\n",
    "        n=self.n\n",
    "\n",
    "        for day_data in data:\n",
    "            nll += n*(1+theta) + (n+(1/theta)) * np.log(1-n + np.sum(np.power(day_data,-theta)))\n",
    "            nll += -np.sum([np.log(u) + np.log(j*theta +1) for j,u in enumerate(day_data)])\n",
    "        \n",
    "        return nll\n",
    "\n",
    "# Bardossy2011+rain_occurence copula\n",
    "\n",
    "# def parallelised nll: global function called during parrallel jobs. \n",
    "\n",
    "def parallel_nll(chunck, Us_didrain_Usbin, norm_us, cov_mat, cov_mat2):\n",
    "    nll = 0\n",
    "    didrain = Us_didrain_Usbin[1]\n",
    "    Us_b = Us_didrain_Usbin[2]\n",
    "    for day in chunck:# contribution of the Zs - normal copula for occurence of rain\n",
    "        nll+=scs.multivariate_normal.logpdf([scs.norm.ppf(obs,loc=0,scale=1) for obs in Us_b[day]],mean=np.zeros(len(Us_b[0])),cov=cov_mat2) \n",
    "        nll+=-np.sum([scs.norm.logpdf(scs.norm.ppf(obs,loc=0,scale=1),loc=0,scale=1) for obs in Us_b[day]])\n",
    "        \n",
    "        for pair in itertools.combinations(range(13),2):#main contribution - bardossy copula for rain\n",
    "            if didrain[day][pair[0]]+didrain[day][pair[1]]==0: #I1\n",
    "                nll += scs.multivariate_normal.logpdf([norm_us[day][pair[0]],norm_us[day][pair[1]]],mean=np.zeros(2),cov=np.matrix([[1, cov_mat[pair[0]][pair[1]]], [cov_mat[pair[0]][pair[1]], 1]]))\n",
    "            if didrain[day][pair[0]]+didrain[day][pair[1]]==1: #I2 - have [1or0]*ll + [0or1]*ll to add the correct amount, depending on where it rained.\n",
    "                nll += (didrain[day][pair[1]])*scs.norm.logpdf((norm_us[day][pair[0]]-norm_us[day][pair[1]]*cov_mat[pair[0]][pair[1]])/(sqrt(1-np.power(cov_mat[pair[0]][pair[1]],2)))) + (1-didrain[day][pair[1]])*scs.norm.logpdf((norm_us[day][pair[1]]-norm_us[day][pair[0]]*cov_mat[pair[0]][pair[1]])/(sqrt(1-np.power(cov_mat[pair[0]][pair[1]],2)))) \n",
    "                nll += (didrain[day][pair[1]])*scs.norm.logpdf(norm_us[day][pair[1]]) + (1-didrain[day][pair[1]])*scs.norm.logpdf(norm_us[day][pair[0]])\n",
    "            if didrain[day][pair[0]]+didrain[day][pair[1]]==0: #I3\n",
    "                nll += scs.multivariate_normal.logcdf([norm_us[day][pair[0]],norm_us[day][pair[1]]],mean=np.zeros(2),cov=np.matrix([[1, cov_mat[pair[0]][pair[1]]], [cov_mat[pair[0]][pair[1]], 1]]))\n",
    "    return nll\n",
    "\n",
    "class cop_bardossy():\n",
    "\n",
    "    def __init__(self,L=np.array([[0,1,1],[1,0,1],[1,1,0]])):\n",
    "        '''\n",
    "        L is location matrix: n x n\n",
    "        '''\n",
    "        self.L=L\n",
    "    \n",
    "    def nll(self,theta,Us_didrain_Usbin): #not parrallelised\n",
    "        '''\n",
    "        theta: [sigma,p0,v0,p1,v1] vector of parameters for the Matern Kernel\n",
    "        Us: [[u1,..,un],...,[...]] one set of (n: one for each location) us for each day 1 to T (T is the number of predictor matricies).\n",
    "        didrain: 0/1 values in the same structure as Us, indicators of rain (1=rain).\n",
    "        '''\n",
    "        nll = 0\n",
    "        Us = Us_didrain_Usbin[0]\n",
    "        didrain = Us_didrain_Usbin[1]\n",
    "        Us_b = Us_didrain_Usbin[2]\n",
    "        theta1,theta2 = theta[0],theta[1]\n",
    "        # transform Us into invNorms\n",
    "        norm_us = [[] for i in range(len(Us)) ]\n",
    "        for day in range(len(Us)):\n",
    "            norm_us[day]=[scs.norm.ppf(u) for u in Us[day]]\n",
    "            \n",
    "        # kernels\n",
    "        cov_mat=np.nan_to_num(RBF(length_scale=theta1).__call__(self.L),copy=False,nan=0)\n",
    "        cov_mat2=np.nan_to_num(RBF(length_scale=theta2).__call__(self.L),copy=False,nan=0)\n",
    "\n",
    "        #loglikelihood\n",
    "\n",
    "        for day in range(len(Us)):# contribution of the Zs - normal copula for occurence of rain\n",
    "            nll+=scs.multivariate_normal.logpdf([scs.norm.ppf(obs,loc=0,scale=1) for obs in Us_b[day]],mean=np.zeros(len(Us_b[0])),cov=cov_mat2) \n",
    "            nll+=-np.sum([scs.norm.logpdf(scs.norm.ppf(obs,loc=0,scale=1),loc=0,scale=1) for obs in Us_b[day]])\n",
    "            for pair in itertools.combinations(range(13),2):#main contribution - bardossy copula for rain\n",
    "                if didrain[day][pair[0]]+didrain[day][pair[1]]==0: #I1\n",
    "                    nll += scs.multivariate_normal.logpdf([norm_us[day][pair[0]],norm_us[day][pair[1]]],mean=np.zeros(2),cov=np.matrix([[1, cov_mat[pair[0]][pair[1]]], [cov_mat[pair[0]][pair[1]], 1]]))\n",
    "                if didrain[day][pair[0]]+didrain[day][pair[1]]==1: #I2 - have [1or0]*ll + [0or1]*ll to add the correct amount, depending on where it rained.\n",
    "                    nll += (didrain[day][pair[1]])*scs.norm.logpdf((norm_us[day][pair[0]]-norm_us[day][pair[1]]*cov_mat[pair[0]][pair[1]])/(sqrt(1-np.power(cov_mat[pair[0]][pair[1]],2)))) + (1-didrain[day][pair[1]])*scs.norm.logpdf((norm_us[day][pair[1]]-norm_us[day][pair[0]]*cov_mat[pair[0]][pair[1]])/(sqrt(1-np.power(cov_mat[pair[0]][pair[1]],2)))) \n",
    "                    nll += (didrain[day][pair[1]])*scs.norm.logpdf(norm_us[day][pair[1]]) + (1-didrain[day][pair[1]])*scs.norm.logpdf(norm_us[day][pair[0]])\n",
    "                if didrain[day][pair[0]]+didrain[day][pair[1]]==0: #I3\n",
    "                    nll += scs.multivariate_normal.logcdf([norm_us[day][pair[0]],norm_us[day][pair[1]]],mean=np.zeros(2),cov=np.matrix([[1, cov_mat[pair[0]][pair[1]]], [cov_mat[pair[0]][pair[1]], 1]]))\n",
    "        return -nll\n",
    "\n",
    "    def p_nll(self,theta,Us_didrain_Usbin): # parallelised\n",
    "        '''\n",
    "        theta: [sigma,p0,v0,p1,v1] vector of parameters for the Matern Kernel\n",
    "        Us: [[u1,..,un],...,[...]] one set of (n: one for each location) us for each day 1 to T (T is the number of predictor matricies).\n",
    "        didrain: 0/1 values in the same structure as Us, indicators of rain (1=rain).\n",
    "        '''\n",
    "        theta1,theta2 = theta[0],theta[1]\n",
    "        Us = Us_didrain_Usbin[0]\n",
    "        # transform Us into invNorms\n",
    "        norm_us = [[] for i in range(len(Us)) ]\n",
    "        for day in range(len(Us)):\n",
    "            norm_us[day]=[scs.norm.ppf(u) for u in Us[day]]\n",
    "            \n",
    "        # kernels\n",
    "        cov_mat=np.nan_to_num(RBF(length_scale=theta1).__call__(self.L),copy=False,nan=0)\n",
    "        cov_mat2=np.nan_to_num(RBF(length_scale=theta2).__call__(self.L),copy=False,nan=0)\n",
    "\n",
    "        #loglikelihood\n",
    "        size = math.ceil(len(Us)/psutil.cpu_count())\n",
    "        days_chuncks = [[i for i in range(len(Us))][x:x+size] for x in range(0,len(Us), size)]\n",
    "        list_nll = Parallel(n_jobs=psutil.cpu_count())(delayed(parallel_nll)(chunck, Us_didrain_Usbin, norm_us, cov_mat, cov_mat2) for chunck in days_chuncks)\n",
    "        \n",
    "        return -np.sum(list_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance matrix for kernel\n",
    "\n",
    "#first create correct set of coordinates for eavch of the 4272 locations:\n",
    "\n",
    "loc_coordinates_4272 = [] # matrix of length 4272 [ [lat1,lon1] , [lat2,lon2] , ... , [lat4272,lon4272] ]\n",
    "for loc in range(344):\n",
    "    for row in range(4):\n",
    "        for col in range(4):\n",
    "            if gamma_outputs[loc][7][row][col]==1: #check if land location\n",
    "                x = [gamma_outputs[loc][6][0],gamma_outputs[loc][6][2]] # coordinates of topleft of big square, eg. [57.75, -5.75]\n",
    "                # rectify the 16by16 square into a 4by4\n",
    "                x[0] = x[0]-0.6\n",
    "                x[1] = x[1]+0.6\n",
    "                # finally, select the correct entry out of the 16 in the 4by4. [lat,lon]\n",
    "                loc_coordinates_4272.append([round(x[0]+row*0.1,2) ,round(x[1]+col*0.1,2)])\n",
    "\n",
    "#Now, can compute distance matrix:\n",
    "dist_mat = distance_matrix(loc_coordinates_4272,loc_coordinates_4272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2115c8df190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([loc_coordinates_4272[i][1] for i in range(3098)],[loc_coordinates_4272[i][0] for i in range(3098)],s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20498762.83935404"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_cop_loconly(L=dist_mat[48:80,48:80]).nll(theta=[3,3],data=[g_us[i][48:80] for i in range(2002)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clayton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77788.18569187525"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clayton(n=16).eval_nll(theta=3,data=[g_us[i][48:80] for i in range(2002)]) # takes 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fval: 14326075.26123136 theta: 0.00806025 time: 1h\n",
    "#dual_annealing(Clayton(n=4272).eval_nll,bounds=[[0.00000001,10]],args=[g_us],maxiter=1000)\n",
    "# first 16: 0.45316421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bardossy 2011 copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load censored us and z_i #1m\n",
    "\n",
    "# 0 'pred_mu', 1'pred_disp', 2'target_did_rain', 3'target_rain_value', 4'date', 5'pred_p', 6'location'.\n",
    "#[place][parameter][day][row][column]\n",
    "#0:i,1:location,2:pred_mu,3:pred_disp,4:pred_p,5:target_rain_value,6:dates\n",
    " #no need to run this part as it's saved with pickle\n",
    "'''censored_us = [[] for i in range(2002)]\n",
    "g_zs = [[] for i in range(2002)]\n",
    "\n",
    "for day in tqdm(range(2002)):\n",
    "    for location in range(267):\n",
    "        for row in range(4):\n",
    "            for column in range(4):\n",
    "                censored_us[day].append(gamma_outputs[location][2][day][row][column])   \n",
    "                g_zs[day].append(np.power(1-gamma_outputs[location][5][day][row][column],1-gamma_outputs[location][2][day][row][column]))   \n",
    "for day in tqdm(range(2002)):\n",
    "    for location in range(len(g_zs[day])):\n",
    "        if g_zs[day][location]>0.999:\n",
    "            g_zs[day][location] = 0.9999\n",
    "        g_zs[day][location] = abs(g_zs[day][location]) '''\n",
    "\n",
    "'''with open('censored_us.txt','wb') as f:\n",
    "    pickle.dump(censored_us,f)\n",
    "with open('g_zs.txt','wb') as f:\n",
    "    pickle.dump(g_zs,f)'''\n",
    "#just load\n",
    "with open('censored_us.txt','rb') as f:\n",
    "    did_rain_01 = pickle.load(f)\n",
    "with open('g_zs.txt','rb') as f:\n",
    "    g_zs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code\\All UK model 1\\Copulas_gamma.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cop_bardossy(L\u001b[39m=\u001b[39mdist_mat[\u001b[39m48\u001b[39m:\u001b[39m80\u001b[39m,\u001b[39m48\u001b[39m:\u001b[39m80\u001b[39m])\u001b[39m.\u001b[39mnll([\u001b[39m0.45\u001b[39m,\u001b[39m0.24\u001b[39m],[[g_us[i][\u001b[39m48\u001b[39m:\u001b[39m80\u001b[39m]\u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m)],[censored_us[i][\u001b[39m48\u001b[39m:\u001b[39m80\u001b[39m]\u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m)],[g_zs[i][\u001b[39m48\u001b[39m:\u001b[39m80\u001b[39m]\u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m300\u001b[39m)]])\n",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code\\All UK model 1\\Copulas_gamma.ipynb Cell 17\u001b[0m in \u001b[0;36mcop_bardossy.nll\u001b[1;34m(self, theta, Us_didrain_Usbin)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m#loglikelihood\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39mfor\u001b[39;00m day \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(Us)):\u001b[39m# contribution of the Zs - normal copula for occurence of rain\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     nll\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mscs\u001b[39m.\u001b[39mmultivariate_normal\u001b[39m.\u001b[39mlogpdf([scs\u001b[39m.\u001b[39mnorm\u001b[39m.\u001b[39mppf(obs,loc\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m Us_b[day]],mean\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(Us_b[\u001b[39m0\u001b[39m])),cov\u001b[39m=\u001b[39mcov_mat2) \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     nll\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum([scs\u001b[39m.\u001b[39mnorm\u001b[39m.\u001b[39mlogpdf(scs\u001b[39m.\u001b[39mnorm\u001b[39m.\u001b[39mppf(obs,loc\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),loc\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m Us_b[day]])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mcombinations(\u001b[39mrange\u001b[39m(\u001b[39m13\u001b[39m),\u001b[39m2\u001b[39m):\u001b[39m#main contribution - bardossy copula for rain\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code\\All UK model 1\\Copulas_gamma.ipynb Cell 17\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39m#loglikelihood\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m \u001b[39mfor\u001b[39;00m day \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(Us)):\u001b[39m# contribution of the Zs - normal copula for occurence of rain\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     nll\u001b[39m+\u001b[39m\u001b[39m=\u001b[39mscs\u001b[39m.\u001b[39mmultivariate_normal\u001b[39m.\u001b[39mlogpdf([scs\u001b[39m.\u001b[39;49mnorm\u001b[39m.\u001b[39;49mppf(obs,loc\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,scale\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m Us_b[day]],mean\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(Us_b[\u001b[39m0\u001b[39m])),cov\u001b[39m=\u001b[39mcov_mat2) \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     nll\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum([scs\u001b[39m.\u001b[39mnorm\u001b[39m.\u001b[39mlogpdf(scs\u001b[39m.\u001b[39mnorm\u001b[39m.\u001b[39mppf(obs,loc\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),loc\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,scale\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m obs \u001b[39min\u001b[39;00m Us_b[day]])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code/All%20UK%20model%201/Copulas_gamma.ipynb#X22sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mcombinations(\u001b[39mrange\u001b[39m(\u001b[39m13\u001b[39m),\u001b[39m2\u001b[39m):\u001b[39m#main contribution - bardossy copula for rain\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2136\u001b[0m, in \u001b[0;36mrv_continuous.ppf\u001b[1;34m(self, q, *args, **kwds)\u001b[0m\n\u001b[0;32m   2134\u001b[0m     goodargs \u001b[39m=\u001b[39m argsreduce(cond, \u001b[39m*\u001b[39m((q,)\u001b[39m+\u001b[39margs\u001b[39m+\u001b[39m(scale, loc)))\n\u001b[0;32m   2135\u001b[0m     scale, loc, goodargs \u001b[39m=\u001b[39m goodargs[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], goodargs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], goodargs[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m-> 2136\u001b[0m     place(output, cond, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ppf(\u001b[39m*\u001b[39;49mgoodargs) \u001b[39m*\u001b[39;49m scale \u001b[39m+\u001b[39m loc)\n\u001b[0;32m   2137\u001b[0m \u001b[39mif\u001b[39;00m output\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   2138\u001b[0m     \u001b[39mreturn\u001b[39;00m output[()]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cop_bardossy(L=dist_mat[48:80,48:80]).nll([0.45,0.24],[[g_us[i][48:80]for i in range(300)],[censored_us[i][48:80]for i in range(300)],[g_zs[i][48:80]for i in range(300)]]) #22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306381.7809577087"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cop_bardossy(L=dist_mat[48:80,48:80]).p_nll([0.1,0.1],[[g_us[i][48:80]for i in range(2002)],[censored_us[i][48:80]for i in range(2002)],[g_zs[i][48:80]for i in range(2002)]]) #22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 112204.5414053855\n",
       " message: ['Maximum number of function call reached during annealing']\n",
       "    nfev: 400\n",
       "    nhev: 0\n",
       "     nit: 92\n",
       "    njev: 10\n",
       "  status: 0\n",
       " success: False\n",
       "       x: array([0.67495809, 0.35775013])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_annealing(cop_bardossy(L=dist_mat[48:80,48:80]).p_nll,bounds=[[0.5,10],[0.25,10]],args=[[[g_us[i][48:80]for i in range(2002)],[censored_us[i][48:80]for i in range(2002)],[g_zs[i][48:80]for i in range(2002)]]],maxfun=400)# 22/1maxfun\n",
    "#0.24580719, 0.49390414 , feval:1123 , 16 locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Gaussian Copula\n",
    "\n",
    "The following are used below. They have the appropriate format for the MLE function, ie: 2002 rows of 4272 entries each, corresponding to 2002 days for 4272 location.\n",
    "\n",
    "g_us : Us from the GNM\\\n",
    "did_rain_01 : indicator for observed rain \\\n",
    "inv_us : normal ppf of Us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load g_us, did_rain, inv_us + remove water locations \n",
    "#list[location][parameter][day]\n",
    "#  0'pred_mu', 1'pred_disp', 2'target_did_rain',3 'target_rain_value',4 'date', 5'pred_p'\n",
    "'''g2_us = [[] for i in range(2002)]\n",
    "for day in tqdm(range(2002)):\n",
    "    for loc in range(len(gamma_outputs)):\n",
    "        for row in range(4):\n",
    "            for column in range(4):\n",
    "                #rv = scs.gamma(scale=m*d,a=1/d) \n",
    "                if gamma_outputs[loc][2][day][row][column]==0: # dry -> 1-p\n",
    "                    g2_us[day].append(1-gamma_outputs[loc][5][day][row][column])\n",
    "                else: # wet -> 1-p + p*gamma\n",
    "                    g2_us[day].append((1-gamma_outputs[loc][5][day][row][column]) + ((gamma_outputs[loc][5][day][row][column])*scs.gamma(scale=gamma_outputs[loc][0][day][row][column]*gamma_outputs[loc][1][day][row][column],a=1/gamma_outputs[loc][1][day][row][column]).cdf(gamma_outputs[loc][3][day][row][column])))\n",
    "                \n",
    "with open('g2_us.txt','wb') as f:\n",
    "    pickle.dump(g2_us,f)\n",
    "\n",
    "inv_us = [[] for i in range(2002)]\n",
    "for day in tqdm(range(2002)):\n",
    "    for loc in range(len(g2_us[0])):\n",
    "        inv_us[day].append(scs.norm.ppf(g2_us[day][loc]))\n",
    "with open('inv_Us.txt','wb') as f:\n",
    "    pickle.dump(inv_us,f)\n",
    "\n",
    "did_rain_01 = [[] for i in range(2002)]\n",
    "for day in tqdm(range(2002)):\n",
    "    for loc in range(len(gamma_outputs)):\n",
    "        for row in range(4):\n",
    "            for column in range(4):\n",
    "                did_rain_01[day].append(gamma_outputs[loc][2][day][row][column])\n",
    "with open('did_rain_01.txt','wb') as f:\n",
    "    pickle.dump(did_rain_01,f)'''\n",
    "with open('inv_Us.txt','rb') as f:\n",
    "    inv_us = pickle.load(f)\n",
    "with open('did_rain_01.txt','rb') as f:\n",
    "    did_rain_01 = pickle.load(f)\n",
    "with open('g2_us.txt','rb') as f:\n",
    "    g2_us = pickle.load(f)\n",
    "\n",
    "g2_us = [[g2_us[i][k] for k in idx_land] for i in range(len(g2_us))]\n",
    "inv_us = [[inv_us[i][k] for k in idx_land] for i in range(len(inv_us))]\n",
    "did_rain_01 = [[did_rain_01[i][k] for k in idx_land] for i in range(len(did_rain_01))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to remove data for water locations using idx_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC estimate - Correct and working\n",
    "def mc_cdf(rvs,cov_matrix,ppf_us):\n",
    "    '''\n",
    "    rvs: [[set1], ... , [set m]] each set of length = #locations = n.\n",
    "    cov_matrix: covariance matrix between the locations in question.\n",
    "    ppf_us: [u1, ... , un] length = # locs.\n",
    "    '''    \n",
    "    # rvs are mean 0 already, but need different covariance\n",
    "    cholesk_mat = np.linalg.cholesky(cov_matrix)\n",
    "    normcov_vars = [np.asarray(cholesk_mat@rvs[i])[0] for i in range(len(rvs))]\n",
    "    out = max(0.0001,np.sum([np.sum([normcov_vars[m][n]<ppf_us[n] for n in range(len(ppf_us))])==len(ppf_us) for m in range(len(normcov_vars))]))\n",
    "    return out/len(rvs)       \n",
    "    \n",
    "    \n",
    "#rand_vars = scs.multivariate_normal.rvs(np.zeros(len(submat11.todense())),np.eye(len(submat11.todense())),size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_vars = scs.multivariate_normal.rvs(np.zeros(len(dist_mat)),np.eye(len(dist_mat)),size=10000)\n",
    "# length = size, each set is of length = #locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncated Gaussian copula class\n",
    "class truncgauss():\n",
    "    def __init__(self,L):\n",
    "        '''\n",
    "        Class to fit and work with a truncated Gaussian copula, using two functions.\n",
    "        sim: simulated [0,1] values using this copula density.\n",
    "        eval_nll: evaluate the negative log likelihood based on given data.\n",
    "        To use the class, the dimension of the data is needed.\n",
    "        n: dimension of data\n",
    "        '''\n",
    "        self.L=L\n",
    "    \n",
    "    def sim(self,theta,draws):\n",
    "        '''\n",
    "        Simulates m draws from the truncated gaussian copula conditional on parameters theta for the covariance kernel.\n",
    "        '''\n",
    "        #later\n",
    "\n",
    "    def nll(self,theta,Invcdf_Us,truncation_pi,did_rain,len_locs,rvs):\n",
    "        cov_mat = np.nan_to_num(RBF(length_scale=theta).__call__(self.L),copy=False,nan=0)\n",
    "        nll=0\n",
    "        for day in tqdm(range(len(Invcdf_Us))): #eg [251,...,500]\n",
    "            \n",
    "            # numerator: joint pdf integrated over truncation - equivalent to elegant normal cdf in some cases. Check cases:\n",
    "            if np.sum(did_rain[day])==len(did_rain[day]): #all wet, just normal pdf\n",
    "                nll += scs.multivariate_normal.logpdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "            else: # some dry -> use elegant cdf\n",
    "                #print('elegant'+str(np.sum(did_rain[day])))\n",
    "                if np.sum(did_rain[day])==0: # all dry -> use normal cdf\n",
    "                    nll += scs.multivariate_normal.logcdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # need to re-arrange the covariance matrix into 2*2 blocks based on censored/uncensored. \n",
    "                    r_rain,c_rain = [[i] for i in np.nonzero(did_rain[day])[0]],[i for i in np.nonzero(did_rain[day])[0]]\n",
    "                    r_dry,c_dry = [[i] for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]],[i for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]]\n",
    "                    \n",
    "                    # create submatricies\n",
    "                    submat11 = coo_matrix(cov_mat[r_dry,c_dry])\n",
    "                    submat12 = csr_matrix(cov_mat[r_dry,c_rain])\n",
    "                    submat21 = csc_matrix(cov_mat[r_rain,c_dry])\n",
    "                    submat22 = coo_matrix(cov_mat[r_rain,c_rain])\n",
    "                    \n",
    "                    #### MC estimate part      ####\n",
    "\n",
    "                    if len(submat22.todense())!=1:\n",
    "                        sub_cov = (submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense()\n",
    "                    else: # submat22 is an integer, aka only one non-zero obs\n",
    "                        sub_cov = (submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense()\n",
    "                    # Do MC approximation to cdf\n",
    "                    nll += np.log(mc_cdf([rvs[i][:len(c_dry)] for i in range(len(rvs))],sub_cov,[inv_us[day][k] for k in c_dry]))\n",
    "\n",
    "                    #### MC estimate part - end ####\n",
    "\n",
    "\n",
    "                    # compute and add the elegant cdf\n",
    "                    #if len(submat22.todense())==1:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense())\n",
    "                    #else:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense())\n",
    "            \n",
    "            # denominator: multiplication of marginals - pdf for positive rain, cdf for truncated\n",
    "            for loc in range(len(Invcdf_Us[0])):\n",
    "                if did_rain[day][loc]==1:# wet: add pdf(invcdf(u_i))\n",
    "                    nll -= scs.norm.logpdf(Invcdf_Us[day][loc],loc=0,scale=1)\n",
    "                else:# dry: add cdf(invcdf(pi))\n",
    "                    nll -= np.log(truncation_pi[day][loc])\n",
    "            \n",
    "        return -nll\n",
    "\n",
    "    def nll_cov_mat(self,Invcdf_Us,truncation_pi,did_rain,days_list,rvs,cov_mat):\n",
    "        nll=0\n",
    "        for day in tqdm(days_list): #eg [251,...,500]\n",
    "            \n",
    "            # numerator: joint pdf integrated over truncation - equivalent to elegant normal cdf in some cases. Check cases:\n",
    "            if np.sum(did_rain[day])==len(did_rain[day]): #all wet, just normal pdf\n",
    "                nll += scs.multivariate_normal.logpdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "            else: # some dry -> use elegant cdf\n",
    "                #print('elegant'+str(np.sum(did_rain[day])))\n",
    "                if np.sum(did_rain[day])==0: # all dry -> use normal cdf\n",
    "                    nll += scs.multivariate_normal.logcdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # need to re-arrange the covariance matrix into 2*2 blocks based on censored/uncensored. \n",
    "                    r_rain,c_rain = [[i] for i in np.nonzero(did_rain[day])[0]],[i for i in np.nonzero(did_rain[day])[0]]\n",
    "                    r_dry,c_dry = [[i] for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]],[i for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]]\n",
    "                    \n",
    "                    # create submatricies\n",
    "                    submat11 = coo_matrix(cov_mat[r_dry,c_dry])\n",
    "                    submat12 = csr_matrix(cov_mat[r_dry,c_rain])\n",
    "                    submat21 = csc_matrix(cov_mat[r_rain,c_dry])\n",
    "                    submat22 = coo_matrix(cov_mat[r_rain,c_rain])\n",
    "                    \n",
    "                    #### MC estimate part      ####\n",
    "\n",
    "                    if len(submat22.todense())!=1:\n",
    "                        sub_cov = (submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense()\n",
    "                    else: # submat22 is an integer, aka only one non-zero obs\n",
    "                        sub_cov = (submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense()\n",
    "                    # Do MC approximation to cdf\n",
    "                    nll += np.log(mc_cdf([rvs[i][:len(c_dry)] for i in range(len(rvs))],sub_cov,[inv_us[day][k] for k in c_dry]))\n",
    "\n",
    "                    #### MC estimate part - end ####\n",
    "\n",
    "\n",
    "                    # compute and add the elegant cdf\n",
    "                    #if len(submat22.todense())==1:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense())\n",
    "                    #else:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense())\n",
    "            \n",
    "            # denominator: multiplication of marginals - pdf for positive rain, cdf for truncated\n",
    "            for loc in range(len(Invcdf_Us[0])):\n",
    "                if did_rain[day][loc]==1:# wet: add pdf(invcdf(u_i))\n",
    "                    nll -= scs.norm.logpdf(Invcdf_Us[day][loc],loc=0,scale=1)\n",
    "                else:# dry: add cdf(invcdf(pi))\n",
    "                    nll -= np.log(truncation_pi[day][loc])\n",
    "            \n",
    "        return -nll\n",
    "\n",
    "    def nll_par(self,theta,Invcdf_Us,truncation_pi,did_rain,len_locs,rvs):\n",
    "               \n",
    "        # broadcasting\n",
    "        backend = Backend()\n",
    "        theta_bds = backend.broadcast(theta)\n",
    "        Invcdf_Us_bds = backend.broadcast(Invcdf_Us)\n",
    "        truncation_pi_bds = backend.broadcast(truncation_pi)\n",
    "        did_rain_bds = backend.broadcast(did_rain)\n",
    "        len_locs_bds = backend.broadcast(len_locs)\n",
    "        rvs_bds = backend.broadcast(rvs)\n",
    "        cov_mat_bds = backend.broadcast(np.nan_to_num(RBF(length_scale=theta).__call__(self.L),copy=False,nan=0))\n",
    "        # preparing for workers\n",
    "        days_arr = range(len(Invcdf_Us))\n",
    "        days_pds = backend.parallelize(days_arr)\n",
    "        nll_once_pds = backend.map(nll_single, days_pds)\n",
    "        nll = backend.collect(nll_once_pds)\n",
    "\n",
    "        return nll\n",
    "\n",
    "    #function for single nll eval\n",
    "\n",
    "    def nll_singl(self,theta,day,Invcdf_Us,truncation_pi,did_rain,rvs,cov_mat,len_locs):\n",
    "        nll=0\n",
    "        for day in [day]: #eg [251,...,500]\n",
    "            \n",
    "            # numerator: joint pdf integrated over truncation - equivalent to elegant normal cdf in some cases. Check cases:\n",
    "            if np.sum(did_rain[day])==len(did_rain[day]): #all wet, just normal pdf\n",
    "                nll += scs.multivariate_normal.logpdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "            else: # some dry -> use elegant cdf\n",
    "                #print('elegant'+str(np.sum(did_rain[day])))\n",
    "                if np.sum(did_rain[day])==0: # all dry -> use normal cdf\n",
    "                    nll += scs.multivariate_normal.logcdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # need to re-arrange the covariance matrix into 2*2 blocks based on censored/uncensored. \n",
    "                    r_rain,c_rain = [[i] for i in np.nonzero(did_rain[day])[0]],[i for i in np.nonzero(did_rain[day])[0]]\n",
    "                    r_dry,c_dry = [[i] for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]],[i for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]]\n",
    "                    \n",
    "                    # create submatricies\n",
    "                    submat11 = coo_matrix(cov_mat[r_dry,c_dry])\n",
    "                    submat12 = csr_matrix(cov_mat[r_dry,c_rain])\n",
    "                    submat21 = csc_matrix(cov_mat[r_rain,c_dry])\n",
    "                    submat22 = coo_matrix(cov_mat[r_rain,c_rain])\n",
    "                    \n",
    "                    #### MC estimate part      ####\n",
    "\n",
    "                    if len(submat22.todense())!=1:\n",
    "                        sub_cov = (submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense()\n",
    "                    else: # submat22 is an integer, aka only one non-zero obs\n",
    "                        sub_cov = (submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense()\n",
    "                    # Do MC approximation to cdf\n",
    "                    nll += np.log(mc_cdf([rvs[i][:len(c_dry)] for i in range(len(rvs))],sub_cov,[inv_us[day][k] for k in c_dry]))\n",
    "\n",
    "                    #### MC estimate part - end ####\n",
    "\n",
    "\n",
    "                    # compute and add the elegant cdf\n",
    "                    #if len(submat22.todense())==1:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense())\n",
    "                    #else:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense())\n",
    "            \n",
    "            # denominator: multiplication of marginals - pdf for positive rain, cdf for truncated\n",
    "            for loc in range(len(Invcdf_Us[0])):\n",
    "                if did_rain[day][loc]==1:# wet: add pdf(invcdf(u_i))\n",
    "                    nll -= scs.norm.logpdf(Invcdf_Us[day][loc],loc=0,scale=1)\n",
    "                else:# dry: add cdf(invcdf(pi))\n",
    "                    nll -= np.log(truncation_pi[day][loc])\n",
    "            \n",
    "        return -nll\n",
    "\n",
    "    def nll_one(self,day,theta,Invcdf_Us,truncation_pi,did_rain,len_locs,rvs,cov_mat):\n",
    "        \n",
    "        nll=0\n",
    "        for day in tqdm([day]): #eg [251,...,500]\n",
    "            \n",
    "            # numerator: joint pdf integrated over truncation - equivalent to elegant normal cdf in some cases. Check cases:\n",
    "            if np.sum(did_rain[day])==len(did_rain[day]): #all wet, just normal pdf\n",
    "                nll += scs.multivariate_normal.logpdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "            else: # some dry -> use elegant cdf\n",
    "                #print('elegant'+str(np.sum(did_rain[day])))\n",
    "                if np.sum(did_rain[day])==0: # all dry -> use normal cdf\n",
    "                    nll += scs.multivariate_normal.logcdf(x=Invcdf_Us[day],mean=np.zeros(len(Invcdf_Us[0])),cov=cov_mat)\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    # need to re-arrange the covariance matrix into 2*2 blocks based on censored/uncensored. \n",
    "                    r_rain,c_rain = [[i] for i in np.nonzero(did_rain[day])[0]],[i for i in np.nonzero(did_rain[day])[0]]\n",
    "                    r_dry,c_dry = [[i] for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]],[i for i in range(len_locs) if i not in np.nonzero(did_rain[day])[0]]\n",
    "                    \n",
    "                    # create submatricies\n",
    "                    submat11 = coo_matrix(cov_mat[r_dry,c_dry])\n",
    "                    submat12 = csr_matrix(cov_mat[r_dry,c_rain])\n",
    "                    submat21 = csc_matrix(cov_mat[r_rain,c_dry])\n",
    "                    submat22 = coo_matrix(cov_mat[r_rain,c_rain])\n",
    "                    \n",
    "                    #### MC estimate part      ####\n",
    "\n",
    "                    if len(submat22.todense())!=1:\n",
    "                        sub_cov = (submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense()\n",
    "                    else: # submat22 is an integer, aka only one non-zero obs\n",
    "                        sub_cov = (submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense()\n",
    "                    # Do MC approximation to cdf\n",
    "                    nll += np.log(mc_cdf([rvs[i][:len(c_dry)] for i in range(len(rvs))],sub_cov,[inv_us[day][k] for k in c_dry]))\n",
    "\n",
    "                    #### MC estimate part - end ####\n",
    "\n",
    "\n",
    "                    # compute and add the elegant cdf\n",
    "                    #if len(submat22.todense())==1:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12*scipy.sparse.linalg.inv(submat22)[0]*submat21).todense())\n",
    "                    #else:\n",
    "                    #    nll += scs.multivariate_normal.logcdf(x=[Invcdf_Us[day][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense())\n",
    "            \n",
    "            # denominator: multiplication of marginals - pdf for positive rain, cdf for truncated\n",
    "            for loc in range(len(Invcdf_Us[0])):\n",
    "                if did_rain[day][loc]==1:# wet: add pdf(invcdf(u_i))\n",
    "                    nll -= scs.norm.logpdf(Invcdf_Us[day][loc],loc=0,scale=1)\n",
    "                else:# dry: add cdf(invcdf(pi))\n",
    "                    nll -= np.log(truncation_pi[day][loc])\n",
    "            \n",
    "        return -nll\n",
    "\n",
    "def nll_single(day):\n",
    "    return truncgauss(L=dist_mat).nll_cov_mat(Invcdf_Us=[inv_us[day]],truncation_pi=[g2_us[day]],did_rain=[did_rain_01[day]],days_list=[day],rvs=rand_vars,cov_mat= test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do rbf on subset of dist_mat based on distance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mat = np.nan_to_num(RBF(length_scale=0.1).__call__(dist_mat),copy=False,nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'len_locs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m truncgauss(L\u001b[39m=\u001b[39mdist_mat[:\u001b[39m100\u001b[39m,:\u001b[39m100\u001b[39m])\u001b[39m.\u001b[39mnll_singl(theta\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,day\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m,Invcdf_Us\u001b[39m=\u001b[39m[inv_us[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m)],truncation_pi\u001b[39m=\u001b[39m[g2_us[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m)],did_rain\u001b[39m=\u001b[39m[did_rain_01[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m)],rvs \u001b[39m=\u001b[39m rand_vars,cov_mat\u001b[39m=\u001b[39mtest_mat)\n",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 27\u001b[0m in \u001b[0;36mtruncgauss.nll_singl\u001b[1;34m(self, theta, day, Invcdf_Us, truncation_pi, did_rain, rvs, cov_mat)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m     \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m     \u001b[39m# need to re-arrange the covariance matrix into 2*2 blocks based on censored/uncensored. \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=157'>158</a>\u001b[0m     r_rain,c_rain \u001b[39m=\u001b[39m [[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mnonzero(did_rain[day])[\u001b[39m0\u001b[39m]],[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mnonzero(did_rain[day])[\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m     r_dry,c_dry \u001b[39m=\u001b[39m [[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(len_locs) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mnonzero(did_rain[day])[\u001b[39m0\u001b[39m]],[i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(len_locs) \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mnonzero(did_rain[day])[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m     \u001b[39m# create submatricies\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X63sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m     submat11 \u001b[39m=\u001b[39m coo_matrix(cov_mat[r_dry,c_dry])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'len_locs' is not defined"
     ]
    }
   ],
   "source": [
    "truncgauss(L=dist_mat[:100,:100]).nll_singl(theta=0.1,day=30,Invcdf_Us=[inv_us[i][:100] for i in range(50)],truncation_pi=[g2_us[i][:100] for i in range(50)],did_rain=[did_rain_01[i][:100] for i in range(50)],rvs = rand_vars,cov_mat=test_mat) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelized_nll(theta):\n",
    "    #covariance matrix - used for the whole nll evaluation\n",
    "    cov_mat = test_mat\n",
    "\n",
    "    # broadcasting\n",
    "    cov_mat_bds = backend.broadcast(cov_mat)\n",
    "\n",
    "    # preparing for workers\n",
    "    days_arr = range(100)\n",
    "    days_pds = backend.parallelize(days_arr)\n",
    "    nll_once_pds = backend.map(nll_single, days_pds)\n",
    "    nll = backend.collect(nll_once_pds)\n",
    "\n",
    "    print(np.sum(nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cov_mat_bds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m parallelized_nll(\u001b[39m0.1\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 29\u001b[0m in \u001b[0;36mparallelized_nll\u001b[1;34m(theta)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m days_arr \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m days_pds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mparallelize(days_arr)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m nll_once_pds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mmap(nll_single, days_pds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m nll \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mcollect(nll_once_pds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39msum(nll))\n",
      "File \u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\..\\parallel\\backends\\base.py:185\u001b[0m, in \u001b[0;36mBackendDummy.map\u001b[1;34m(self, func, pds)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39mThis is a wrapper for the Python internal map function.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m    a new pseudo-parallel data set that contains the result of the map\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m result_map \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(func, pds\u001b[39m.\u001b[39mpython_list)\n\u001b[1;32m--> 185\u001b[0m result_pds \u001b[39m=\u001b[39m PDSDummy(\u001b[39mlist\u001b[39;49m(result_map))\n\u001b[0;32m    186\u001b[0m \u001b[39mreturn\u001b[39;00m result_pds\n",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 29\u001b[0m in \u001b[0;36mnll_single\u001b[1;34m(day)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnll_single\u001b[39m(day):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m truncgauss(L\u001b[39m=\u001b[39mdist_mat[:\u001b[39m100\u001b[39m,:\u001b[39m100\u001b[39m])\u001b[39m.\u001b[39mnll_one(theta\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,day\u001b[39m=\u001b[39mday,Invcdf_Us\u001b[39m=\u001b[39m[inv_us[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m)],truncation_pi\u001b[39m=\u001b[39m[g2_us[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m)],did_rain\u001b[39m=\u001b[39m[did_rain_01[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m)],len_locs\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(g2_us[\u001b[39m0\u001b[39m][:\u001b[39m100\u001b[39m]),rvs \u001b[39m=\u001b[39m rand_vars,cov_mat\u001b[39m=\u001b[39mcov_mat_bds\u001b[39m.\u001b[39mvalue())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cov_mat_bds' is not defined"
     ]
    }
   ],
   "source": [
    "parallelized_nll(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_single(day):\n",
    "    return truncgauss(L=dist_mat[:100,:100]).nll_one(theta=0.1,day=day,Invcdf_Us=[inv_us[i][:100] for i in range(2002)],truncation_pi=[g2_us[i][:100] for i in range(2002)],did_rain=[did_rain_01[i][:100] for i in range(2002)],len_locs=len(g2_us[0][:100]),rvs = rand_vars,cov_mat=cov_mat_bds.value()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cov_mat_bds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nll_single(\u001b[39m1000\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 31\u001b[0m in \u001b[0;36mnll_single\u001b[1;34m(day)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnll_single\u001b[39m(day):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X65sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m truncgauss(L\u001b[39m=\u001b[39mdist_mat[:\u001b[39m100\u001b[39m,:\u001b[39m100\u001b[39m])\u001b[39m.\u001b[39mnll_one(theta\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,day\u001b[39m=\u001b[39mday,Invcdf_Us\u001b[39m=\u001b[39m[inv_us[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m)],truncation_pi\u001b[39m=\u001b[39m[g2_us[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m)],did_rain\u001b[39m=\u001b[39m[did_rain_01[i][:\u001b[39m100\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m)],len_locs\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(g2_us[\u001b[39m0\u001b[39m][:\u001b[39m100\u001b[39m]),rvs \u001b[39m=\u001b[39m rand_vars,cov_mat\u001b[39m=\u001b[39mcov_mat_bds\u001b[39m.\u001b[39mvalue())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cov_mat_bds' is not defined"
     ]
    }
   ],
   "source": [
    "nll_single(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:144: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  warn('spsolve requires A be CSC or CSR matrix format',\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:215: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n",
      "100%|| 1/1 [00:00<00:00, 14.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-92.75156095308297"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncgauss(L=dist_mat[:100,:100]).nll_one(theta=0.1,day=30,Invcdf_Us=[inv_us[i][:100] for i in range(50)],truncation_pi=[g2_us[i][:100] for i in range(50)],did_rain=[did_rain_01[i][:100] for i in range(50)],len_locs=len(g2_us[0][:100]),rvs = rand_vars) \n",
    "# MC scales well. Big problem is theta changing to higher values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC integral is working well\n",
    "Now parallelise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parallel.backends import BackendMPI as Backend\n",
    "backend = Backend()\n",
    "X_bds = backend.broadcast(X)\n",
    "Y_bds = backend.broadcast(Y)\n",
    "\n",
    "    \n",
    "\n",
    "seed_arr = [ind for ind in range(2002)]\n",
    "seed_pds = backend.parallelize(seed_arr)\n",
    "accepted_parameters_pds = backend.map(myfunc, seed_pds)\n",
    "accepted_parameters = backend.collect(accepted_parameters_pds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_cdf([rand_vars[i][:100] for i in range(len(rand_vars))],sub_cov,[inv_us[day][k] for k in c_dry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_cdf(rand_vars,(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense(),[inv_us[60][k] for k in c_dry])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying sparse matricies - gives cdf=0 for squares larger than 500*500-ish -> logcdf=-inf and crashes for bigger dimensions\n",
    "# try mc approximation to the integral\n",
    "test3 = np.nan_to_num(RBF(length_scale=0.9).__call__(dist_mat),copy=False,nan=0)\n",
    "subset=np.random.choice(range(len(test3)),10,replace=False)\n",
    "r_rain,c_rain = [[i] for i in subset],[i for i in subset]\n",
    "r_dry,c_dry = [[i] for i in range(len(test3)) if i not in subset],[i for i in range(len(test3)) if i not in subset]\n",
    "submat11 = coo_matrix(test3[r_dry,c_dry])\n",
    "submat12 = csr_matrix(test3[r_dry,c_rain])\n",
    "submat21 = csc_matrix(test3[r_rain,c_dry])\n",
    "submat22 = coo_matrix(test3[r_rain,c_rain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:144: SparseEfficiencyWarning: spsolve requires A be CSC or CSR matrix format\n",
      "  warn('spsolve requires A be CSC or CSR matrix format',\n",
      "c:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\linalg\\dsolve\\linsolve.py:215: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  warn('spsolve is more efficient when sparse b '\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\david\\Desktop\\PhD research\\M Dissertation work\\SpaDep_VCop\\Copula Code - Copy\\All UK model 1\\Copulas_gamma.ipynb Cell 31\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/david/Desktop/PhD%20research/M%20Dissertation%20work/SpaDep_VCop/Copula%20Code%20-%20Copy/All%20UK%20model%201/Copulas_gamma.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scs\u001b[39m.\u001b[39mmultivariate_normal\u001b[39m.\u001b[39mcdf([inv_us[\u001b[39m60\u001b[39m][k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m c_dry],mean\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(submat11\u001b[39m.\u001b[39mtodense())),cov\u001b[39m=\u001b[39m(submat11\u001b[39m-\u001b[39msubmat12\u001b[39m@scipy\u001b[39m\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(submat22)\u001b[39m@submat21\u001b[39m)\u001b[39m.\u001b[39mtodense())\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_multivariate.py:626\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.cdf\u001b[1;34m(self, x, mean, cov, allow_singular, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m maxpts:\n\u001b[0;32m    625\u001b[0m     maxpts \u001b[39m=\u001b[39m \u001b[39m1000000\u001b[39m \u001b[39m*\u001b[39m dim\n\u001b[1;32m--> 626\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cdf(x, mean, cov, maxpts, abseps, releps)\n\u001b[0;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_multivariate.py:550\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._cdf\u001b[1;34m(self, x, mean, cov, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[39m# mvnun expects 1-d arguments, so process points sequentially\u001b[39;00m\n\u001b[0;32m    548\u001b[0m func1d \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x_slice: mvn\u001b[39m.\u001b[39mmvnun(lower, x_slice, mean, cov,\n\u001b[0;32m    549\u001b[0m                                    maxpts, abseps, releps)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 550\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(func1d, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x)\n\u001b[0;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m _squeeze_output(out)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    377\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    378\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    381\u001b[0m \u001b[39m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[0;32m    385\u001b[0m buff \u001b[39m=\u001b[39m zeros(inarr_view\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mshape, res\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\stats\\_multivariate.py:548\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._cdf.<locals>.<lambda>\u001b[1;34m(x_slice)\u001b[0m\n\u001b[0;32m    546\u001b[0m lower \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(mean\u001b[39m.\u001b[39mshape, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf)\n\u001b[0;32m    547\u001b[0m \u001b[39m# mvnun expects 1-d arguments, so process points sequentially\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m func1d \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x_slice: mvn\u001b[39m.\u001b[39;49mmvnun(lower, x_slice, mean, cov,\n\u001b[0;32m    549\u001b[0m                                    maxpts, abseps, releps)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    550\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(func1d, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, x)\n\u001b[0;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m _squeeze_output(out)\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "scs.multivariate_normal.cdf([inv_us[60][k] for k in c_dry],mean=np.zeros(len(submat11.todense())),cov=(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_var = scs.multivariate_normal.rvs(np.zeros(len(submat11.todense())),np.eye(len(submat11.todense())),size=10)\n",
    "mc_cdf(rand_var,(submat11-submat12@scipy.sparse.linalg.inv(submat22)@submat21).todense(),[inv_us[60][k] for k in c_dry])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try subsampling to avoid 0 days\n",
    "# look for faster normal cdf computations - found no multivariate ones, only univariate cdf: scipy.special.ndtr\n",
    "\n",
    "try Mc:\n",
    "sample 1M from normal, and check proportion of samples within d_i area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1700/1700 [00:18<00:00, 92.34it/s]\n",
      "100%|| 1700/1700 [00:19<00:00, 85.28it/s]\n",
      "100%|| 1700/1700 [03:28<00:00,  8.15it/s]\n",
      "100%|| 1700/1700 [25:50<00:00,  1.10it/s]\n",
      "100%|| 1700/1700 [53:45<00:00,  1.90s/it]\n",
      "100%|| 1700/1700 [1:07:29<00:00,  2.38s/it]\n",
      "100%|| 1700/1700 [1:20:43<00:00,  2.85s/it]\n",
      "100%|| 1700/1700 [1:22:57<00:00,  2.93s/it]\n",
      "100%|| 1700/1700 [1:27:29<00:00,  3.09s/it]\n",
      "100%|| 1700/1700 [1:28:53<00:00,  3.14s/it]\n",
      "  5%|         | 88/1700 [04:56<1:30:37,  3.37s/it]it]\n",
      " 29%|       | 10/35 [8:16:12<20:40:32, 2977.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\u1819911\\Desktop\\Copula Work\\Copula code\\All UK model 1\\Copulas_gamma.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m theta \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m35\u001b[39m)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     subset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mrange\u001b[39m(\u001b[39m2002\u001b[39m),\u001b[39m1700\u001b[39m,replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mle_tests\u001b[39m.\u001b[39mappend(truncgauss(L\u001b[39m=\u001b[39;49mdist_mat[:\u001b[39m20\u001b[39;49m,:\u001b[39m20\u001b[39;49m])\u001b[39m.\u001b[39;49mnll(theta\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m0.1\u001b[39;49m\u001b[39m*\u001b[39;49mtheta,Invcdf_Us\u001b[39m=\u001b[39;49m[inv_us[i][:\u001b[39m20\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m subset],truncation_pi\u001b[39m=\u001b[39;49m[g_us[i][:\u001b[39m20\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m subset],did_rain\u001b[39m=\u001b[39;49m[did_rain_01[i][:\u001b[39m20\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m subset],len_locs\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(g2_us[\u001b[39m0\u001b[39;49m][:\u001b[39m20\u001b[39;49m])))\n",
      "\u001b[1;32mc:\\Users\\u1819911\\Desktop\\Copula Work\\Copula code\\All UK model 1\\Copulas_gamma.ipynb Cell 39\u001b[0m in \u001b[0;36mtruncgauss.nll\u001b[1;34m(self, theta, Invcdf_Us, truncation_pi, did_rain, len_locs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m         submat22 \u001b[39m=\u001b[39m cov_mat[r_rain,c_rain]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m         \u001b[39m# compute and add the elegant cdf\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m         nll \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m scs\u001b[39m.\u001b[39;49mmultivariate_normal\u001b[39m.\u001b[39;49mlogcdf(x\u001b[39m=\u001b[39;49m[Invcdf_Us[day][k] \u001b[39mfor\u001b[39;49;00m k \u001b[39min\u001b[39;49;00m c_dry],mean\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mzeros(\u001b[39mlen\u001b[39;49m(submat11)),cov\u001b[39m=\u001b[39;49msubmat11\u001b[39m-\u001b[39;49mnp\u001b[39m.\u001b[39;49mmatmul(np\u001b[39m.\u001b[39;49mmatmul(submat12,np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(submat22)),submat21))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# denominator: multiplication of marginals - pdf for positive rain, cdf for truncated\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/u1819911/Desktop/Copula%20Work/Copula%20code/All%20UK%20model%201/Copulas_gamma.ipynb#X52sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(Invcdf_Us[\u001b[39m0\u001b[39m])):\n",
      "File \u001b[1;32mc:\\Users\\u1819911\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py:588\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.logcdf\u001b[1;34m(self, x, mean, cov, allow_singular, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m maxpts:\n\u001b[0;32m    587\u001b[0m     maxpts \u001b[39m=\u001b[39m \u001b[39m1000000\u001b[39m \u001b[39m*\u001b[39m dim\n\u001b[1;32m--> 588\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cdf(x, mean, cov, maxpts, abseps, releps))\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\u1819911\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py:550\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._cdf\u001b[1;34m(self, x, mean, cov, maxpts, abseps, releps)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[39m# mvnun expects 1-d arguments, so process points sequentially\u001b[39;00m\n\u001b[0;32m    548\u001b[0m func1d \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x_slice: mvn\u001b[39m.\u001b[39mmvnun(lower, x_slice, mean, cov,\n\u001b[0;32m    549\u001b[0m                                    maxpts, abseps, releps)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 550\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mapply_along_axis(func1d, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x)\n\u001b[0;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m _squeeze_output(out)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\u1819911\\Anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    376\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    377\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    378\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 379\u001b[0m res \u001b[39m=\u001b[39m asanyarray(func1d(inarr_view[ind0], \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m    381\u001b[0m \u001b[39m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[0;32m    385\u001b[0m buff \u001b[39m=\u001b[39m zeros(inarr_view\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mshape, res\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\u1819911\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py:548\u001b[0m, in \u001b[0;36mmultivariate_normal_gen._cdf.<locals>.<lambda>\u001b[1;34m(x_slice)\u001b[0m\n\u001b[0;32m    546\u001b[0m lower \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(mean\u001b[39m.\u001b[39mshape, \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf)\n\u001b[0;32m    547\u001b[0m \u001b[39m# mvnun expects 1-d arguments, so process points sequentially\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m func1d \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x_slice: mvn\u001b[39m.\u001b[39;49mmvnun(lower, x_slice, mean, cov,\n\u001b[0;32m    549\u001b[0m                                    maxpts, abseps, releps)[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m    550\u001b[0m out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mapply_along_axis(func1d, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, x)\n\u001b[0;32m    551\u001b[0m \u001b[39mreturn\u001b[39;00m _squeeze_output(out)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mle_tests = []\n",
    "for theta in tqdm(range(0,35)):\n",
    "    subset = np.random.choice(range(2002),1700,replace=False)\n",
    "    mle_tests.append(truncgauss(L=dist_mat[:20,:20]).nll(theta=0.01+0.1*theta,Invcdf_Us=[inv_us[i][:20] for i in subset],truncation_pi=[g_us[i][:20] for i in subset],did_rain=[did_rain_01[i][:20] for i in subset],len_locs=len(g2_us[0][:20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mle_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20b8d69e700>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.01+0.1*i for i in range(0,10)],mle_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q:\n",
    "SGD for subsets of spatial grid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    " - Replace cdf by MC estimate in nll\n",
    " - parallelise after that using ritos package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72f235a78b5cf937fd09c1593b6a0e4473f824a03930b62c2c7d9a177b9de8f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
