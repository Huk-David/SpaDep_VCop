{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################### Loading packages ####################################################################\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math \n",
    "import re\n",
    "from Censored_copula import truncgauss\n",
    "from scipy.spatial import distance_matrix\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import psutil\n",
    "from sklearn import metrics\n",
    "import scipy.integrate as integrate\n",
    "import sys\n",
    "import os\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "#################################################################### Loading GNM ####################################################################\n",
    "model_version = 0\n",
    "target_distribution = \"\"\n",
    "base_nn = \"VAEGAN\"\n",
    "sys.path.append('../')\n",
    "import glms\n",
    "import pickle\n",
    "import torch\n",
    "path_ = f\"Checkpoints/{base_nn}{target_distribution}/lightning_logs/version_{model_version}/\"\n",
    "#ckpt_path = glms.NeuralDGLM.get_ckpt_path(os.path.join(path_,\"checkpoints\"))\n",
    "ckpt_path = 'Checkpoints/VAEGAN/lightning_logs/version_0/checkpoints/epoch=46-step=7567-val_fid=181.166.ckpt'\n",
    "print([path_,ckpt_path])\n",
    "\n",
    "GNM_output = pickle.load( open(os.path.join(path_,\"test_output_1999_2019-07.pkl\"),\"rb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_x = []\n",
    "locations_y = []\n",
    "indexes_land = []\n",
    "for y_loc in range(100):\n",
    "    for x_loc in range(140):\n",
    "        if GNM_output['mask'][3][y_loc,x_loc]==True:\n",
    "            if 100-y_loc>-18.75+(25/80)*x_loc:\n",
    "                locations_x.append(x_loc)\n",
    "                locations_y.append(-y_loc)\n",
    "                indexes_land.append([y_loc,x_loc])\n",
    "\n",
    "dist_mat = distance_matrix(np.array(indexes_land),np.array(indexes_land))\n",
    "\n",
    "GNM_output.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warwing: check if the correct locations were removed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw time-series plot with quantiles for predicted vs trget rain at a given location. ~3s \n",
    "# Just change values at the top.\n",
    "\n",
    "#ts_plot_location = 3055\n",
    "for ts_plot_location in [954]:\n",
    "    print(ts_plot_location)\n",
    "    ts_plot_left_lim,ts_plot_right_lim = ts_plot_location+0,ts_plot_location+0+360\n",
    "\n",
    "    #################################################################### Do not touch the rest ####################################################################\n",
    "    import matplotlib.dates as mdates\n",
    "\n",
    "    # mean and 68, 95 percentiles \n",
    "    g_median = []\n",
    "    g_q25 = []\n",
    "    g_q75 = []\n",
    "    g_q68 = []\n",
    "    g_q95 = []\n",
    "    g_q32 = []\n",
    "    g_q05 = []\n",
    "\n",
    "    #GNM_landonly[location][param][day]\n",
    "    # 0'pred_alpha', 1'pred_beta', 2 rain>0 , 3'target_rain', 4 pred_p, 5 loc\n",
    "    for a,b,i in zip([GNM_landonly[ts_plot_location][0][i] for i in range(len(GNM_landonly[0][0]))],[GNM_landonly[ts_plot_location][1][i] for i in range(len(GNM_landonly[0][0]))],range(len(GNM_landonly[0][0]))) :\n",
    "        rv = scs.gamma(scale=1/b,a=a)  \n",
    "        \n",
    "        g_median.append(rv.ppf((GNM_landonly[ts_plot_location][4][i]-1+0.5)/GNM_landonly[ts_plot_location][4][i]))\n",
    "        g_q25.append(rv.ppf((GNM_landonly[ts_plot_location][4][i]-1+0.25)/GNM_landonly[ts_plot_location][4][i]))\n",
    "        g_q75.append(rv.ppf((GNM_landonly[ts_plot_location][4][i]-1+0.75)/GNM_landonly[ts_plot_location][4][i]))\n",
    "        g_q95.append(rv.ppf((GNM_landonly[ts_plot_location][4][i]-1+0.95)/GNM_landonly[ts_plot_location][4][i]))\n",
    "        g_q05.append(rv.ppf((GNM_landonly[ts_plot_location][4][i]-1+0.05)/GNM_landonly[ts_plot_location][4][i]))\n",
    "\n",
    "    for q in [g_median,g_q25,g_q05,g_q32,g_q68,g_q75,g_q95]:\n",
    "        for i in range(len(q)):\n",
    "            if math.isnan(q[i]):\n",
    "                q[i]=0\n",
    "                \n",
    "    plt.figure(figsize=(25, 8),dpi=700)\n",
    "    plt.plot(day_dates,g_q05,color='skyblue',linewidth=0.6,alpha=1,label='forecast percentiles 05 to 95')\n",
    "    plt.plot(day_dates,g_q25,color='navy',linewidth=0.6,alpha=1,label='forecast percentiles 25 to 75')\n",
    "    plt.plot(day_dates,g_median,color='blue',linewidth=1,alpha=1,label='forcast median')\n",
    "    plt.plot(day_dates,g_q75,color='navy',linewidth=0.6,alpha=1)\n",
    "    plt.plot(day_dates,g_q95,color='skyblue',linewidth=0.6,alpha=1)\n",
    "    plt.fill_between(day_dates, g_median, g_q75, where=([g_median[k] < g_q75[k] for k in range(len(GNM_landonly[ts_plot_location][4]))]), color='navy', alpha=0.6,interpolate=True)\n",
    "    plt.fill_between(day_dates, g_median, g_q25, where=([g_median[k] > g_q25[k] for k in range(len(GNM_landonly[ts_plot_location][4]))]), color='navy', alpha=0.6,interpolate=True)\n",
    "    plt.fill_between(day_dates, g_q95, g_q75, where=([g_q95[k] > g_q75[k] for k in range(len(GNM_landonly[ts_plot_location][4]))]), color='skyblue', alpha=0.6,interpolate=True)\n",
    "    plt.fill_between(day_dates, g_q05, g_q25, where=([g_q05[k] < g_q25[k] for k in range(len(GNM_landonly[ts_plot_location][4]))]), color='skyblue', alpha=0.6,interpolate=True)\n",
    "    plt.scatter(day_dates,[GNM_landonly[ts_plot_location][3][i] for i in range(len(GNM_landonly[0][0]))],color='r',marker='1',s=20,label='observed rain')\n",
    "    plt.plot(day_dates,[GNM_landonly[ts_plot_location][3][i] for i in range(len(GNM_landonly[0][0]))],color='r',alpha=0.6,linewidth=0.3)\n",
    "    plt.xlim((day_dates[ts_plot_left_lim],day_dates[ts_plot_right_lim]))\n",
    "    plt.title('Gamma model at location '+str(GNM_landonly[ts_plot_location][5]))\n",
    "    plt.xlabel('Day index')\n",
    "    plt.ylabel('Precipitation (mm)')\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=14))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densities plots\n",
    "# Just change values at the top.\n",
    "\n",
    "density_plot_location = 111\n",
    "density_plot_start,density_plot_end = 370,376\n",
    "\n",
    "#################################################################### Do not touch the rest ####################################################################\n",
    "import matplotlib\n",
    "\n",
    "# 0'pred_alpha', 1'pred_beta', 2 rain>0 , 3'target_rain', 4 pred_p, 5 loc\n",
    "x=[i/20 for i in range(400)]\n",
    "plt.figure(figsize=(10,(density_plot_end-density_plot_start)*2))\n",
    "colors = matplotlib.cm.viridis(np.linspace(0, 1, len(range(density_plot_end,density_plot_start,-1))))\n",
    "for idx,col in zip(reversed(range(density_plot_start-1,density_plot_end)),colors):\n",
    "    rv=scs.gamma(a=[GNM_landonly[density_plot_location][0][i] for i in range(len(GNM_landonly[ts_plot_location][4]))][idx],scale=[1/GNM_landonly[density_plot_location][1][i] for i in range(len(GNM_landonly[ts_plot_location][4]))][idx])\n",
    "    level=(-0.3+(idx+1-density_plot_start)*0.25)\n",
    "    plt.plot(x,level+rv.pdf(x),color='black',alpha=0.7)\n",
    "    plt.fill_between(x,y1=level+rv.pdf(x),y2=level,where=([level+rv.pdf(x_)>level for x_ in x]),color=col,alpha=0.5)\n",
    "    plt.text(15,level+0.03,'p= '+str(round([GNM_landonly[density_plot_location][4][i] for i in range(len(GNM_landonly[ts_plot_location][4]))][idx],2)))\n",
    "    plt.scatter([GNM_landonly[density_plot_location][3][i] for i in range(len(GNM_landonly[ts_plot_location][4]))][idx],level,marker='v',color='b')\n",
    "plt.xlabel('Precipitation (mm)')\n",
    "plt.title('Gamma(y) in location '+str(GNM_landonly[density_plot_location][5]))\n",
    "#plt.yticks([-0.3+(idx-density_plot_start)*0.25 for idx in range(density_plot_end,density_plot_start,-1)],reversed([pd.to_datetime(i).date() for i in GNM_output[location_keys[0]]['date'][density_plot_start:density_plot_end]]))\n",
    "#plt.yticks([-0.3+(idx-density_plot_start)*0.25 for idx in range(density_plot_end,density_plot_start,-1)],[k for k in range([density_plot_start:density_plot_end]])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_subset = np.random.choice(range(len(GNM_output['target_rain'])),size=256,replace=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = np.array([np.array([GNM_output['pred_rain_ensemble'][d][i[0]][i[1]] for i in indexes_land]) for d in tqdm(range(len(GNM_output['pred_rain_ensemble']))) ])\n",
    "# all_sims[day,loc,sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(1):\n",
    "    plt.scatter(locations_x,locations_y,c=[GNM_output['target_rain'][d][i[0],i[1]] for i in indexes_land],cmap='inferno_r',s=3)\n",
    "    plt.title('true')\n",
    "    plt.show()\n",
    "    plt.scatter(locations_x,locations_y,c=np.median(all_sims[d],axis=1),cmap='inferno_r',s=3)\n",
    "    plt.title('median')\n",
    "    plt.show()\n",
    "    plt.scatter(locations_x,locations_y,c=np.mean(all_sims[d],axis=1),cmap='inferno_r',s=3)\n",
    "    plt.title('mean')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_roc(day,x):\n",
    "   \n",
    "   out = 1-(\n",
    "         (1-np.array([GNM_landonly[l][4][day] for l in range(len(GNM_landonly))])) + \n",
    "         np.multiply(\n",
    "            [GNM_landonly[l][4][day] for l in range(len(GNM_landonly))] , \n",
    "            scs.gamma( scale=[1/GNM_landonly[l][1][day] for l in range(len(GNM_landonly))] , \n",
    "                        a=[GNM_landonly[l][0][day] for l in range(len(GNM_landonly))]\n",
    "               ).cdf(x)\n",
    "            )        \n",
    "      )\n",
    "\n",
    "   return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting vector of 'did it rain this much'\n",
    "g_0mm=[]\n",
    "g_5mm=[]\n",
    "g_10mm=[]\n",
    "g_15mm=[]\n",
    "g_20mm=[]\n",
    "g_25mm=[]\n",
    "\n",
    "#GNM_landonly[location][param][day]\n",
    "# 0'pred_alpha', 1'pred_beta', 2 rain>0 , 3'target_rain', 4 pred_p, 5 loc\n",
    "\n",
    "def fast_roc(day,x):\n",
    "   \n",
    "   out = 1-(\n",
    "         (1-np.array([GNM_landonly[l][4][day] for l in range(len(GNM_landonly))])) + \n",
    "         np.multiply(\n",
    "            [GNM_landonly[l][4][day] for l in range(len(GNM_landonly))] , \n",
    "            scs.gamma( scale=[1/GNM_landonly[l][1][day] for l in range(len(GNM_landonly))] , \n",
    "                        a=[GNM_landonly[l][0][day] for l in range(len(GNM_landonly))]\n",
    "               ).cdf(x)\n",
    "            )        \n",
    "      )\n",
    "\n",
    "   return out\n",
    "\n",
    "\n",
    "for d in tqdm(range(len(GNM_landonly[0][0]))):\n",
    "   g_0mm.append(fast_roc(d,0.01))\n",
    "   g_5mm.append(fast_roc(d,5))\n",
    "   g_10mm.append(fast_roc(d,10))\n",
    "   g_15mm.append(fast_roc(d,15))\n",
    "   g_20mm.append(fast_roc(d,20))\n",
    "   g_25mm.append(fast_roc(d,25))\n",
    "\n",
    "\n",
    "with open('g_0mm.txt','wb') as f:\n",
    "   pickle.dump(g_0mm,f)\n",
    "\n",
    "with open('g_5mm.txt','wb') as f:\n",
    "   pickle.dump(g_5mm,f)\n",
    "\n",
    "with open('g_10mm.txt','wb') as f:\n",
    "   pickle.dump(g_10mm,f)\n",
    "\n",
    "with open('g_15mm.txt','wb') as f:\n",
    "   pickle.dump(g_15mm,f)\n",
    "\n",
    "with open('g_20mm.txt','wb') as f:\n",
    "   pickle.dump(g_20mm,f)\n",
    "\n",
    "with open('g_25mm.txt','wb') as f:\n",
    "   pickle.dump(g_25mm,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_0mm_did_rain=[]\n",
    "g_5mm_did_rain=[]\n",
    "g_10mm_did_rain=[]\n",
    "g_15mm_did_rain=[]\n",
    "g_20mm_did_rain=[]\n",
    "g_25mm_did_rain=[]\n",
    "def roc_didrain(day,x):\n",
    "    return np.array([GNM_landonly[l][3][day] for l in range(len(GNM_landonly))])>x\n",
    "for d in tqdm(range(len(GNM_landonly[0][0]))):\n",
    "   g_0mm_did_rain.append(roc_didrain(d,0.01))\n",
    "   g_5mm_did_rain.append(roc_didrain(d,5))\n",
    "   g_10mm_did_rain.append(roc_didrain(d,10))\n",
    "   g_15mm_did_rain.append(roc_didrain(d,15))\n",
    "   g_20mm_did_rain.append(roc_didrain(d,20))\n",
    "   g_25mm_did_rain.append(roc_didrain(d,25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving data\n",
    "'''with open('g_0mm.txt','wb') as f:\n",
    "    pickle.dump(g_0mm,f)\n",
    "with open('g_5mm.txt','wb') as f:\n",
    "    pickle.dump(g_5mm,f)\n",
    "with open('g_10mm.txt','wb') as f:\n",
    "    pickle.dump(g_10mm,f)\n",
    "with open('g_15mm.txt','wb') as f:\n",
    "    pickle.dump(g_15mm,f)\n",
    "with open('g_20mm.txt','wb') as f:\n",
    "    pickle.dump(g_20mm,f)\n",
    "with open('g_25mm.txt','wb') as f:\n",
    "    pickle.dump(g_25mm,f)'''\n",
    "\n",
    "# Loading data\n",
    " \n",
    "with open('g_0mm.txt','rb') as f:\n",
    "    g_0mm = pickle.load(f)\n",
    "with open('g_5mm.txt','rb') as f:\n",
    "    g_5mm = pickle.load(f)\n",
    "with open('g_10mm.txt','rb') as f:\n",
    "    g_10mm = pickle.load(f)\n",
    "with open('g_15mm.txt','rb') as f:\n",
    "    g_15mm = pickle.load(f)\n",
    "with open('g_20mm.txt','rb') as f:\n",
    "    g_20mm = pickle.load(f)\n",
    "with open('g_25mm.txt','rb') as f:\n",
    "    g_25mm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructuring data for ROC ~1m+3m/20y , 6m/30y\n",
    "\n",
    "# g_25mm[loc][parallel run][0:rained more than x, 1:P it rained x][days]\n",
    "roc_0_tf = np.array(g_0mm_did_rain).flatten()\n",
    "roc_0_p = np.array(g_0mm).flatten()\n",
    "\n",
    "roc_5_tf = np.array(g_5mm_did_rain).flatten()\n",
    "roc_5_p = np.array(g_5mm).flatten()\n",
    "\n",
    "roc_10_tf = np.array(g_10mm_did_rain).flatten()\n",
    "roc_10_p = np.array(g_10mm).flatten()\n",
    "\n",
    "roc_15_tf = np.array(g_15mm_did_rain).flatten()\n",
    "roc_15_p = np.array(g_15mm).flatten()\n",
    "\n",
    "roc_20_tf = np.array(g_20mm_did_rain).flatten()\n",
    "roc_20_p = np.array(g_20mm).flatten()\n",
    "\n",
    "roc_25_tf = np.array(g_25mm_did_rain).flatten()\n",
    "roc_25_p = np.array(g_25mm).flatten()\n",
    "\n",
    "###\n",
    "\n",
    "fpr_0mm, tpr_0mm, _ = metrics.roc_curve(roc_0_tf,roc_0_p)\n",
    "auc0 = metrics.roc_auc_score(roc_0_tf,roc_0_p)\n",
    "\n",
    "fpr_5mm, tpr_5mm, _ = metrics.roc_curve(roc_5_tf,roc_5_p)\n",
    "auc5 = metrics.roc_auc_score(roc_5_tf,roc_5_p)\n",
    "\n",
    "fpr_10mm, tpr_10mm, _ = metrics.roc_curve(roc_10_tf,roc_10_p)\n",
    "auc10 = metrics.roc_auc_score(roc_10_tf,roc_10_p)\n",
    "\n",
    "fpr_15mm, tpr_15mm, _ = metrics.roc_curve(roc_15_tf,roc_15_p)\n",
    "auc15 = metrics.roc_auc_score(roc_15_tf,roc_15_p)\n",
    "\n",
    "fpr_20mm, tpr_20mm, _ = metrics.roc_curve(roc_20_tf,roc_20_p)\n",
    "auc20 = metrics.roc_auc_score(roc_20_tf,roc_20_p)\n",
    "\n",
    "fpr_25mm, tpr_25mm, _ = metrics.roc_curve(roc_25_tf,roc_25_p)\n",
    "auc25 = metrics.roc_auc_score(roc_25_tf,roc_25_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC plot ~3m\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(fpr_0mm,tpr_0mm,label='AUC='+str(auc0),color='black',alpha=0.7)\n",
    "\n",
    "plt.plot(fpr_5mm,tpr_5mm,label='AUC='+str(auc5),color='red',alpha=0.7)\n",
    "\n",
    "plt.plot(fpr_10mm,tpr_10mm,label='AUC='+str(auc10),color='orange',alpha=0.7,linestyle='dashed')\n",
    "\n",
    "plt.plot(fpr_15mm,tpr_15mm,label='AUC='+str(auc15),color='green',alpha=0.7,linestyle='dashdot')\n",
    "\n",
    "plt.plot(fpr_20mm,tpr_20mm,label='AUC='+str(auc20),color='blue',alpha=0.7,linestyle='dotted')\n",
    "\n",
    "plt.plot(fpr_25mm,tpr_25mm,label='AUC='+str(auc25),color='purple',alpha=0.7)\n",
    "\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(['0mm '+str(round(auc0,5)),'5mm '+str(round(auc5,5)),'10mm '+str(round(auc10,5)),'15mm '+str(round(auc15,5)),'20mm '+str(round(auc20,5)),'25mm '+str(round(auc25,5))])\n",
    "#plt.title('Gamma Model United Kingdom')\n",
    "#plt.savefig('ROC Gamma model UK')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(rain>x) ~1m15 now. depending on samples and days used. \n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "\n",
    "# get empirical cdfs for median, sampled and target rain.\n",
    "gamma_ecdf = ECDF(np.array([np.median(all_sims[d],axis=1) for d in day_subset]).flatten())\n",
    "target_ecdf = ECDF(np.array([[GNM_output['target_rain'][d][i[0],i[1]] for i in indexes_land] for d in tqdm(range(len(GNM_output['target_rain'])))]).flatten())\n",
    "gamma_sampled_ecdf = ECDF(all_sims[day_subset].flatten())\n",
    "plt.plot(gamma_ecdf.x,1-gamma_ecdf.y,label='Median forecast')\n",
    "plt.plot(gamma_sampled_ecdf.x,1-gamma_sampled_ecdf.y,linestyle='dotted',label='Sampled forecasts')\n",
    "plt.plot(target_ecdf.x,1-target_ecdf.y,linestyle='--',label='Target rainfall')\n",
    "plt.xlabel('Precipitation (mm)')\n",
    "plt.ylabel('Probability of precipitatoin > x')\n",
    "plt.xlim(-1,25)\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSB MAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSB and MAB metrics across sub sampled locations and all days \n",
    "\n",
    "# all_sims[day][loc][sim]\n",
    "subdays_target_rain = np.array([[GNM_output['target_rain'][d][i[0],i[1]] for i in indexes_land] for d in day_subset])\n",
    "subdays_median = np.array([np.median(all_sims[d],axis=1) for d in day_subset])\n",
    "\n",
    "RMSB = math.sqrt(np.mean(np.power(np.subtract(subdays_target_rain,subdays_median),2)))\n",
    "MAB = np.mean(np.abs(subdays_median,subdays_target_rain))\n",
    "print('MAB = '+str(MAB)+', RMSB = '+str(RMSB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median VS Observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median vs observed\n",
    "binned_median_means = [np.log(np.mean(g_median_all[np.logical_and(all_target_rain.flatten()>-0.01+k*3, all_target_rain.flatten()<3+k*3     )])+1) for k in range(30)]\n",
    "binned_median_std = [np.std(np.log(1+g_median_all[np.logical_and(all_target_rain.flatten()>-0.01+k*3, all_target_rain.flatten()<3+k*3     )])) for k in range(30)]\n",
    "\n",
    "plt.plot(np.log([i for i in range(1,30*3,3)]),binned_median_means, color='red',linestyle='dashed',label='Mean/SD of pred in 3mm/day intervals')\n",
    "\n",
    "for i,v in enumerate(range(1,30*3,3)):\n",
    "    if i==0:\n",
    "        continue\n",
    "    plt.plot(np.log([v,v]),[binned_median_means[i]+binned_median_std[i] ,binned_median_means[i]-binned_median_std[i] ],'r',linewidth=1)\n",
    "\n",
    "plt.plot([0,5],[0,5],linestyle='dashed',color='grey',label='y = x')\n",
    "plt.scatter(np.log(all_target_rain.flatten()+1),np.log(g_median_all+1),marker='x',linewidths=0.3,alpha=0.3)\n",
    "\n",
    "plt.axvline(x = np.log(10), color = 'purple', label = '10 mm rainfall',linewidth=1.3)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.xlabel('Observed log-trandformed rainfall')\n",
    "plt.ylabel('Predicted log-trandformed rainfall')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CRPS per locatoin. This is done in the medium benchmark paper. Also, I can then plot CRPs on a map, could be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_CRPS_score(observation, simulations):\n",
    "    \"\"\"observation is a single value, while simulations is an array. We estimate this by building an empirical\n",
    "    unbiased estimate of Eq. (1) in Ziel and Berk 2019\"\"\"\n",
    "    diff_X_y = np.abs(observation - simulations)\n",
    "    n_sim = simulations.shape[0]\n",
    "    diff_X_tildeX = np.abs(simulations.reshape(1, -1) - simulations.reshape(-1, 1))\n",
    "    return 2 * np.mean(diff_X_y) - np.sum(diff_X_tildeX) / (n_sim * (n_sim - 1))\n",
    "\n",
    "def exact_CRPS_score(y_obs,F):\n",
    "    def I(x):\n",
    "        return np.power(F(x)-(x>y_obs),2)\n",
    "    return integrate.quad(lambda x: I(x), -0.1,10e+3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_CRPS_score_fast(obs,sims):\n",
    "    '''\n",
    "    obs: one vector of observations [y_1, y_2, ... y_n], ideally n corresponds to locations.\n",
    "    sims: m vectors of simulations, each vector has length n. [[x_11, x_21,..., x_n1] ,..., [x_1m, x_2m,..., x_nm] ]\n",
    "\n",
    "    returns: a vector [s1, ... , sn] of one score per location. this is for a single day, so would still need to average across days.\n",
    "    '''\n",
    "    m = len(sims)\n",
    "\n",
    "    obs= np.array(obs)\n",
    "    sims=np.array(sims)\n",
    "\n",
    "    # |X-x|    \n",
    "    diff_X_x = np.mean(\n",
    "        np.abs(\n",
    "            np.tile(obs,(m,1)) - sims\n",
    "            ),\n",
    "        axis=0)\n",
    "\n",
    "    #|X-X'|\n",
    "    diff_X_tilde_X = np.sum(\n",
    "        np.abs(\n",
    "            np.tile(sims,(m,1))-\n",
    "            np.repeat(sims,m,axis=0)\n",
    "            )\n",
    "            ,axis=0\n",
    "        )/(m*m-1)\n",
    "\n",
    "    return 2*diff_X_x - diff_X_tilde_X \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(all_sims[day_subset[0]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_crps = []\n",
    "for day_idx,day in tqdm(enumerate(day_subset)):\n",
    "    q_crps.append( estimate_CRPS_score_fast(subdays_target_rain[day_idx],np.transpose(all_sims[day])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean CRPS:\n",
    "np.mean(q_crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf() \n",
    "fig.set_size_inches(14,10)\n",
    "plt.scatter(locations_x,locations_y,c=np.mean(q_crps,axis=0),s=22,marker='s')\n",
    "plt.colorbar()\n",
    "plt.title('mean CRPS per location')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Scoring Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spatial_Energy_Score_single_day(beta,observations_y,simulations_Y):\n",
    "\n",
    "    n = len(observations_y)\n",
    "    m = len(simulations_Y)\n",
    "    observations_y = np.array(observations_y)\n",
    "    simulations_Y = np.array(simulations_Y)\n",
    "\n",
    "    # First part |Y-y|. Gives the L2 dist scaled by power beta. Is a vector of length n/one value per location.\n",
    "    diff_Y_y = np.power(\n",
    "            np.linalg.norm(\n",
    "                np.tile(observations_y,(m,1)) -\n",
    "                simulations_Y,\n",
    "            axis=1),\n",
    "        beta)\n",
    "\n",
    "    #Second part |Y-Y'|. 2* because pdist counts only once.\n",
    "    diff_Y_Y = 2 * np.power(\n",
    "        pdist(simulations_Y)\n",
    "    ,beta)\n",
    "\n",
    "    Energy = 2 * np.mean(diff_Y_y) - np.sum(diff_Y_Y)/(m*(m-1))\n",
    "    return Energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Energy_diagnostic = []\n",
    "for i,d in tqdm(enumerate(range(256))):\n",
    "    Energy_diagnostic.append(Spatial_Energy_Score_single_day(0.2,subdays_target_rain[i],np.transpose(all_sims[d])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Energy_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Energy_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Variogram_single_day(observations_y,simulations_Y,distance_matrix):\n",
    "\n",
    "    n = len(observations_y)\n",
    "    m = len(simulations_Y)\n",
    "    y = np.array(observations_y)\n",
    "    Y = np.array(simulations_Y)\n",
    "\n",
    "    # inverse distance matrix, for weights w_ij:\n",
    "    w_ij = np.nan_to_num( 1/distance_matrix, copy=False, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "    # |y_i - y_j| first part of Variogram\n",
    "    diff_y_y = euclidean_distances(y.reshape(-1,1))\n",
    "\n",
    "    # |Y_k,i - Y_k,j| second part of Variogram\n",
    "    diff_Y_Y = np.mean(np.abs(np.tile(Y,n).reshape(m,n*n)-np.repeat(Y,n).reshape(m,n*n)),axis=0).reshape(n,n)\n",
    "\n",
    "    Variogram = np.multiply(\n",
    "        w_ij,\n",
    "        np.power(\n",
    "            diff_y_y - diff_Y_Y\n",
    "        ,2)\n",
    "    )\n",
    "\n",
    "    return np.sum(Variogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Variogram_diagnostic = []\n",
    "for i,d in tqdm(enumerate(range(256))):\n",
    "    Variogram_diagnostic.append(Variogram_single_day(subdays_target_rain[i],np.transpose(all_sims[d]),dist_mat) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Variogram_diagnostic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GNM_landonly[location][param][day]\n",
    "# 0'pred_mu', 1'pred_disp', 2'target_did_rain', 3'target_rain_value', 4'pred_p', 5'location'\n",
    "\n",
    "def get_cdf_gnm(day):\n",
    "    p_times_cdf = np.multiply( #p*cdf(y)\n",
    "        np.array([GNM_landonly[l][4][day] for l in range(len(GNM_landonly))]),\n",
    "        scs.gamma(\n",
    "            a=[GNM_landonly[l][0][day] for l in range(len(GNM_landonly))],\n",
    "            scale=[1/GNM_landonly[l][1][day] for l in range(len(GNM_landonly))]\n",
    "            ).cdf([GNM_landonly[l][3][day] for l in range(len(GNM_landonly))]))\n",
    "    \n",
    "    where_0 = np.argwhere(p_times_cdf==0).flatten()\n",
    "    where_rain = np.argwhere(p_times_cdf>0).flatten()\n",
    "\n",
    "    p_times_cdf[where_0] = np.random.uniform( # replace censored by u~[0,1-p]\n",
    "        low=np.zeros(len(where_0)),\n",
    "        high=(1-np.array([GNM_landonly[l][4][day] for l in range(len(GNM_landonly))])[where_0]).flatten()\n",
    "        )\n",
    "    \n",
    "    p_times_cdf[where_rain] = (1-np.array([GNM_landonly[l][4][day] for l in range(len(GNM_landonly))]))[where_rain] + p_times_cdf[where_rain] # uncensored = (1-p) + p*cdf(y)\n",
    "\n",
    "    return p_times_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_u_all = []\n",
    "for d in tqdm(range(len(GNM_landonly[0][0]))):\n",
    "    obs_u_all.append(get_cdf_gnm(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_u_all = np.array(obs_u_all).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.scatter( range(len(obs_u_all)),obs_u_all,s=0.000005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,6.5))\n",
    "plt.hist(obs_u_all,bins=30,density=True,alpha=0.7)\n",
    "plt.plot([0,1],[1,1])\n",
    "plt.ylim(0,3)\n",
    "plt.show()\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.hist(obs_u_all,bins=100,density=True,alpha=0.7)\n",
    "plt.plot([0,1],[1,1])   \n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(obs_u_all,bins=100,cumulative=True,alpha=0.7,align='mid')\n",
    "plt.plot([0,1],[0,len(obs_u_all)],linestyle='dashed')\n",
    "plt.show()\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.hist(obs_u_all,bins=500,cumulative=True,alpha=0.7,align='mid',histtype='step',linewidth=2)\n",
    "plt.plot([0,1],[0,len(obs_u_all)],linestyle='dashed')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72f235a78b5cf937fd09c1593b6a0e4473f824a03930b62c2c7d9a177b9de8f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
